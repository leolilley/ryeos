# Agent Transcript & Telemetry — Implementation Plan

> What we're building now. Single-turn threaded directives with rich transcripts,
> auto-markdown, structured thread metadata, and telemetry.
>
> See [agent-threads-future.md](agent-threads-future.md) for multi-turn,
> cross-thread communication, and async/await execution modes.

## Problem Statement

Current thread transcripts (`.ai/threads/{id}/transcript.jsonl`) are minimal:

- Only capture `thread_start` and `thread_complete` events
- No per-message user/assistant content is recorded
- No tool call input/output detail
- No streaming-as-you-go transcript file
- No human-readable markdown output

Example of current transcript (useless for debugging):

```jsonl
{"ts":"...","type":"thread_start","directive":"hello_world","inputs":{...},"model":"claude-3-5-haiku-20241022","provider":"rye/agent/providers/anthropic_messages"}
{"ts":"...","type":"thread_complete","usage":{...},"cost":{...},"tool_results_count":1}
```

## Thread ID Format

Thread IDs use the format `{directive_name}-{epoch_seconds}` where `epoch_seconds`
is seconds since 1970-01-01 UTC. Example: `hello_world-1739012630`.

Generated by `_generate_thread_id()` in `thread_directive.py`. Clashes (same
directive spawned twice in the same second) are detected against `registry.db`
and raise `ValueError`.

## Storage: Project-Local

All thread data lives in `.ai/threads/` within the project. Rationale:

- Threads operate on project context (files, directives, tools are project-scoped)
- `registry.db` already lives project-local
- Transcripts reference project-relative paths in tool calls
- Can be `.gitignore`d or optionally tracked
- Fits data-driven philosophy: threads are data artifacts of project execution

User-space threads (`~/.ai/threads/`) are a future concern — only needed when
user-space directives spawn cross-project threads. Not building that now.

## Reference: What OpenCode Does

Analyzed from source at `/home/leo/projects/opencode/packages/opencode/`.

### Data Model — Session → Message → Part

```
Session.Info          one session (= our "thread")
  ├── MessageV2.Info  one message (user or assistant turn)
  │   ├── TextPart       assistant text content
  │   ├── ReasoningPart  thinking/chain-of-thought
  │   ├── ToolPart       tool call with state machine (pending → running → completed/error)
  │   ├── StepStartPart  marks beginning of an LLM roundtrip
  │   ├── StepFinishPart marks end + cost/tokens for that step
  │   ├── SubtaskPart    child agent spawn
  │   └── CompactionPart context compaction marker
  └── ...
```

### Transcript Rendering (`packages/opencode/src/cli/cmd/tui/util/transcript.ts`)

~100-line formatter that renders structured parts to markdown with options:
`{ thinking: bool, toolDetails: bool, assistantMetadata: bool }`

### Storage

Individual JSON files per entity: `storage/session/{project}/{id}.json`,
`storage/message/{session}/{id}.json`, `storage/part/{message}/{id}.json`.
All under `~/.local/share/opencode/storage/` (user-global, not project-local).

We differ: project-local `.ai/threads/`, JSONL as source of truth, `.md` as
derived view. No per-entity JSON files for now (JSONL serves this purpose).

---

## What We Build Now

### 1. Rich Transcript Events

Upgrade `TranscriptWriter` and `thread_directive.py` to emit granular events
into `transcript.jsonl` **as they happen during execution**.

Every event includes `directive` to identify which instruction produced it.

#### Event Schema

All events share a common envelope:

```json
{
  "ts": "2026-02-09T04:03:50.365852+00:00",
  "type": "event_type",
  "thread_id": "hello_world-1739012630",
  "directive": "hello_world",
  ...event-specific fields
}
```

#### Event Envelope Contract

Every event written to `transcript.jsonl` MUST include these four fields:
- `ts` — ISO 8601 timestamp (UTC), set by `TranscriptWriter`
- `type` — event type string
- `thread_id` — thread identifier, set by `TranscriptWriter`
- `directive` — directive name, MUST be provided via `data` or `TranscriptWriter.default_directive`. Raises `ValueError` if missing.

Payload fields from `data` are merged into the envelope. If `data` contains `ts`, `type`,
or `thread_id`, they are overridden by the envelope values. The `directive` field in `data`
takes precedence over `default_directive`.

#### Event Types

| Event Type            | When                           | Payload                                                   |
| --------------------- | ------------------------------ | --------------------------------------------------------- |
| `thread_start`        | Thread begins                  | `inputs`, `model`, `provider`, `thread_mode`              |
| `user_message`        | System/user prompt sent to LLM | `text`, `role`                                            |
| `step_start`          | LLM roundtrip begins           | `turn_number`                                             |
| `assistant_text`      | Assistant text response        | `text`                                                    |
| `assistant_reasoning` | Thinking/CoT (if available)    | `text`                                                    |
| `tool_call_start`     | Tool invocation begins         | `tool`, `call_id`, `input`                                |
| `tool_call_result`    | Tool invocation completes      | `call_id`, `output`, `error?`, `duration_ms`              |
| `step_finish`         | LLM roundtrip done             | `cost`, `tokens`, `finish_reason`                         |
| `thread_complete`     | Thread finishes successfully   | `usage`, `cost`, `tool_results_count`                     |
| `thread_error`        | Thread fails                   | `error_code`, `detail`                                    |
| `hook_triggered`      | Hook fired                     | `hook_directive`, `event_name`                            |
| `spawn_child`         | Child thread spawned           | `child_thread_id`, `child_directive`                      |

#### Where to Emit in `thread_directive.py`

```python
# 1. Thread start (extend with thread_mode)
transcript.write_event(thread_id, "thread_start", {
    "inputs": inputs,
    "model": model_id, "provider": provider_id,
    "thread_mode": "single",
})

# 2. System prompt sent
transcript.write_event(thread_id, "user_message", {
    "text": system_prompt, "role": "system",
})

# 3. Before each LLM call
transcript.write_event(thread_id, "step_start", {
    "turn_number": harness.cost.turns + 1,
})

# 4. After LLM response text
transcript.write_event(thread_id, "assistant_text", {
    "text": llm_result["text"],
})

# 5. Per tool call (before execution)
transcript.write_event(thread_id, "tool_call_start", {
    "tool": tool_name, "call_id": call_id,
    "input": tool_input,
})

# 6. Per tool call (after execution)
transcript.write_event(thread_id, "tool_call_result", {
    "call_id": call_id, "output": truncated_output,
    "error": error_str, "duration_ms": duration,
})

# 7. After LLM roundtrip
transcript.write_event(thread_id, "step_finish", {
    "cost": step_cost, "tokens": step_tokens,
    "finish_reason": stop_reason,
})

# 8. Completion (extend)
transcript.write_event(thread_id, "thread_complete", {
    "usage": usage, "cost": cost_dict,
    "tool_results_count": count,
})

# On error
transcript.write_event(thread_id, "thread_error", {
    "error_code": "llm_call_failed",
    "detail": llm_result.get("error", ""),
})
```

### 2. Auto-Generated Markdown Transcript

Extend `TranscriptWriter` to produce `transcript.md` alongside `transcript.jsonl`
in real-time. Enables `tail -f .ai/threads/{id}/transcript.md` during execution.

````python
class TranscriptWriter:
    def __init__(self, transcript_dir: Path, auto_markdown: bool = True, default_directive: str | None = None):
        self.transcript_dir = Path(transcript_dir)
        self.auto_markdown = auto_markdown
        self.default_directive = default_directive

    def write_event(self, thread_id: str, event_type: str, data: Dict) -> None:
        jsonl_path = self.transcript_dir / thread_id / "transcript.jsonl"
        jsonl_path.parent.mkdir(parents=True, exist_ok=True)
        ts = datetime.now(timezone.utc).isoformat()

        directive = data.get("directive") or self.default_directive
        if not directive:
            raise ValueError(
                f"Event '{event_type}' missing 'directive'. "
                f"Provide it in data or set default_directive on TranscriptWriter."
            )

        event = {
            "ts": ts,
            "type": event_type,
            "thread_id": thread_id,
            "directive": directive,
            **{k: v for k, v in data.items() if k not in ("ts", "type", "thread_id", "directive")},
        }
        with open(jsonl_path, "a") as f:
            f.write(json.dumps(event) + "\n")

        if self.auto_markdown:
            md_path = self.transcript_dir / thread_id / "transcript.md"
            md_chunk = self._render_event_to_markdown(event)
            if md_chunk:
                with open(md_path, "a") as f:
                    f.write(md_chunk)

    def _render_event_to_markdown(self, event: Dict) -> str:
        """Render a single event to a markdown fragment."""
        match event.get("type"):
            case "thread_start":
                return (
                    f"# {event.get('directive', 'Thread')}\n\n"
                    f"**Thread ID:** {event.get('thread_id', '')}\n"
                    f"**Model:** {event.get('model', '')}\n"
                    f"**Started:** {event.get('ts', '')}\n\n---\n\n"
                )
            case "user_message":
                role = event.get("role", "user").title()
                return f"## {role}\n\n{event.get('text', '')}\n\n---\n\n"
            case "assistant_text":
                return f"## Assistant\n\n{event.get('text', '')}\n\n"
            case "assistant_reasoning":
                return f"_Thinking:_\n\n{event.get('text', '')}\n\n"
            case "tool_call_start":
                result = f"**Tool: {event.get('tool', '')}**\n"
                inp = event.get("input")
                if inp:
                    result += f"\n**Input:**\n```json\n{json.dumps(inp, indent=2)}\n```\n"
                return result
            case "tool_call_result":
                output = event.get("output", "")
                error = event.get("error")
                if error:
                    return f"\n**Error:**\n```\n{error}\n```\n\n"
                return f"\n**Output:**\n```\n{output}\n```\n\n"
            case "step_finish":
                cost = event.get("cost", {})
                tokens = event.get("tokens", {})
                return (
                    f"_Step: {tokens.get('input_tokens', 0)}in "
                    f"/ {tokens.get('output_tokens', 0)}out "
                    f"· ${cost.get('spend', 0):.4f}_\n\n---\n\n"
                )
            case "thread_complete":
                cost = event.get("cost", {})
                return (
                    f"---\n\n**Completed** · "
                    f"{cost.get('turns', 0)} turns · "
                    f"{cost.get('tokens', 0)} tokens · "
                    f"${cost.get('spend', 0):.4f} · "
                    f"{cost.get('duration_seconds', 0):.1f}s\n"
                )
            case "thread_error":
                return f"---\n\n**Error:** {event.get('error_code', '')} — {event.get('detail', '')}\n"
            case _:
                return ""
````

### 3. Thread Metadata File (`thread.json`)

Write a `thread.json` at thread start, update at completion. Provides quick
access to thread metadata without parsing JSONL.

```
.ai/threads/{thread_id}/
  ├── transcript.jsonl     # append-only event stream (existing, enriched)
  ├── transcript.md        # auto-generated human-readable (new)
  └── thread.json          # metadata snapshot (new)
```

```json
{
  "thread_id": "hello_world-1739012630",
  "directive": "hello_world",
  "model": "claude-3-5-haiku-20241022",
  "provider": "rye/agent/providers/anthropic_messages",
  "status": "completed",
  "thread_mode": "single",
  "parent_thread_id": null,
  "created_at": "2026-02-09T04:03:50Z",
  "updated_at": "2026-02-09T04:04:01Z",
  "inputs": { "output_path": "..." },
  "cost": {
    "turns": 2,
    "tokens": 3778,
    "input_tokens": 3520,
    "output_tokens": 258,
    "spend": 0.003848,
    "duration_seconds": 11.45
  }
}
```

#### Required and Optional Fields

| Field           | Required? | Set When    | Description                                     |
| --------------- | --------- | ----------- | ----------------------------------------------- |
| `thread_id`     | Yes       | Start       | Thread identifier                               |
| `directive`     | Yes       | Start       | Directive name                                  |
| `model`         | Yes       | Start       | LLM model identifier                            |
| `provider`      | Yes       | Start       | Provider tool path                              |
| `status`        | Yes       | Start       | `running`, `completed`, `error`, `paused`       |
| `thread_mode`   | Yes       | Start       | `single` (future: `conversation`, `channel`)    |
| `created_at`    | Yes       | Start       | ISO 8601 UTC timestamp                          |
| `updated_at`    | Yes       | Start+End   | ISO 8601 UTC timestamp, updated on completion   |
| `inputs`        | Optional  | Start       | Directive inputs                                |
| `parent_thread_id` | Optional | Start    | Parent thread ID for child threads              |
| `cost`          | Optional  | Completion  | Cost dict from `CostTracker.to_dict()`          |
| `error`         | Optional  | Error       | `{"code": "...", "detail": "..."}`              |

Written by `thread_directive.py`:

- **On start:** write with `status: "running"`, no cost data
- **On complete:** update `status: "completed"`, fill cost/usage
- **On error:** update `status: "error"`, add error info

### 4. Standalone Transcript Renderer Tool

New tool: `rye/agent/threads/transcript_renderer.py`

Reads an existing `transcript.jsonl` and produces markdown. Useful for:

- Re-rendering with different options after the fact
- Exporting/copying transcripts
- CLI usage: `python transcript_renderer.py --thread-id hello_world-1739012630`

```python
@dataclass
class TranscriptOptions:
    thinking: bool = False
    tool_details: bool = True
    assistant_metadata: bool = True

class TranscriptRenderer:
    def __init__(self, options: TranscriptOptions = None):
        self.options = options or TranscriptOptions()

    def render(self, thread_id: str, project_path: Path) -> str:
        """Read transcript.jsonl and produce full markdown transcript."""
        jsonl_path = project_path / ".ai" / "threads" / thread_id / "transcript.jsonl"
        events = []
        with open(jsonl_path) as f:
            for line in f:
                line = line.strip()
                if line:
                    events.append(json.loads(line))
        return self._format_events(events)

    def _format_events(self, events: list) -> str:
        chunks = []
        for event in events:
            if event.get("type") == "assistant_reasoning" and not self.options.thinking:
                continue
            chunk = self._render_single_event(event)
            if chunk:
                chunks.append(chunk)
        return "".join(chunks)

    def _render_single_event(self, event: Dict) -> str:
        """Render one event to markdown. Same logic as TranscriptWriter._render_event_to_markdown."""
        match event.get("type"):
            case "thread_start":
                return (
                    f"# {event.get('directive', 'Thread')}\n\n"
                    f"**Thread ID:** {event.get('thread_id', '')}\n"
                    f"**Model:** {event.get('model', '')}\n"
                    f"**Started:** {event.get('ts', '')}\n\n---\n\n"
                )
            case "user_message":
                role = event.get("role", "user").title()
                return f"## {role}\n\n{event.get('text', '')}\n\n---\n\n"
            case "assistant_text":
                text = event.get('text', '')
                if self.options.assistant_metadata:
                    return f"## Assistant\n\n{text}\n\n"
                return f"{text}\n\n"
            case "tool_call_start":
                if not self.options.tool_details:
                    return f"**Tool: {event.get('tool', '')}**\n\n"
                result = f"**Tool: {event.get('tool', '')}**\n"
                inp = event.get("input")
                if inp:
                    result += f"\n**Input:**\n```json\n{json.dumps(inp, indent=2)}\n```\n"
                return result
            case "tool_call_result":
                if not self.options.tool_details:
                    return ""
                output = event.get("output", "")
                error = event.get("error")
                if error:
                    return f"\n**Error:**\n```\n{error}\n```\n\n"
                return f"\n**Output:**\n```\n{output}\n```\n\n"
            case "step_finish":
                cost = event.get("cost", {})
                tokens = event.get("tokens", {})
                return (
                    f"_Step: {tokens.get('input_tokens', 0)}in "
                    f"/ {tokens.get('output_tokens', 0)}out "
                    f"· ${cost.get('spend', 0):.4f}_\n\n---\n\n"
                )
            case "thread_complete":
                cost = event.get("cost", {})
                return (
                    f"---\n\n**Completed** · "
                    f"{cost.get('turns', 0)} turns · "
                    f"{cost.get('tokens', 0)} tokens · "
                    f"${cost.get('spend', 0):.4f} · "
                    f"{cost.get('duration_seconds', 0):.1f}s\n"
                )
            case "thread_error":
                return f"---\n\n**Error:** {event.get('error_code', '')} — {event.get('detail', '')}\n"
            case _:
                return ""
```

### 5. Telemetry Aggregation

New tool: `rye/agent/threads/telemetry.py`

Reads `thread.json` files across all threads to produce aggregate stats.

```python
class ThreadTelemetry:
    def aggregate(self, project_path: Path, days: int = 7) -> Dict:
        threads_dir = project_path / ".ai" / "threads"
        now = datetime.now(timezone.utc)
        stats = {"total": 0, "completed": 0, "error": 0,
                 "total_spend": 0.0, "total_tokens": 0,
                 "by_directive": {}, "by_model": {}}

        for thread_dir in threads_dir.iterdir():
            meta_path = thread_dir / "thread.json"
            if not meta_path.exists():
                continue
            try:
                meta = json.loads(meta_path.read_text())
            except json.JSONDecodeError:
                continue

            # Filter by date range
            try:
                created = datetime.fromisoformat(meta["created_at"])
            except (ValueError, KeyError):
                continue
            if (now - created).days > days:
                continue

            stats["total"] += 1
            stats[meta["status"]] = stats.get(meta["status"], 0) + 1
            cost = meta.get("cost", {})
            stats["total_spend"] += cost.get("spend", 0)
            stats["total_tokens"] += cost.get("tokens", 0)

            # Group by directive
            d = meta["directive"]
            stats["by_directive"].setdefault(d, {"count": 0, "spend": 0})
            stats["by_directive"][d]["count"] += 1
            stats["by_directive"][d]["spend"] += cost.get("spend", 0)

        return stats
```

---

## Thread Directory Layout (Final)

```
.ai/threads/
  ├── registry.db                               # SQLite registry (existing, unchanged)
  ├── hello_world-1739012630/
  │   ├── thread.json                           # metadata snapshot (new)
  │   ├── transcript.jsonl                      # rich event stream (existing, enriched)
  │   └── transcript.md                         # auto-generated markdown (new)
  ├── append_cost_report-1739098830/
  │   ├── thread.json
  │   ├── transcript.jsonl
  │   └── transcript.md
  └── ...
```

## Files to Modify

1. **`rye/rye/.ai/tools/rye/agent/threads/thread_registry.py`**
   - Extend `TranscriptWriter` with `auto_markdown` and `_render_event_to_markdown()`
   - Add `directive` to event envelope

2. **`rye/rye/.ai/tools/rye/agent/threads/thread_directive.py`**
   - Add transcript writes at each LLM loop stage (system prompt, step start/finish, assistant text, tool calls)
   - Write `thread.json` at start and update at completion/error

3. **New: `rye/rye/.ai/tools/rye/agent/threads/transcript_renderer.py`**
   - Standalone markdown renderer with options
   - CLI entrypoint for export

4. **New: `rye/rye/.ai/tools/rye/agent/threads/telemetry.py`**
   - Aggregate stats from `thread.json` files

## JSONL Integrity & Error Handling

JSONL files are append-only and written by potentially concurrent processes
(parent + child threads, hooks). They can get corrupted by crashes, disk full,
or external modification. Best practices for defensive handling:

### Writing: Atomic Line Appends

```python
def write_event(self, thread_id: str, event_type: str, data: Dict) -> None:
    jsonl_path = self.transcript_dir / thread_id / "transcript.jsonl"
    jsonl_path.parent.mkdir(parents=True, exist_ok=True)

    ts = datetime.now(timezone.utc).isoformat()
    event = {"ts": ts, "type": event_type, **data}
    line = json.dumps(event, separators=(",", ":")) + "\n"

    # Atomic append: single write call under PIPE_BUF (4096 on Linux)
    # guarantees no interleaving from concurrent writers on POSIX.
    # For lines exceeding PIPE_BUF, use file locking.
    if len(line.encode("utf-8")) > 4096:
        import fcntl
        with open(jsonl_path, "a") as f:
            fcntl.flock(f, fcntl.LOCK_EX)
            try:
                f.write(line)
                f.flush()
            finally:
                fcntl.flock(f, fcntl.LOCK_UN)
    else:
        with open(jsonl_path, "a") as f:
            f.write(line)
```

### Reading: Line-Level Fault Tolerance

Never assume every line is valid JSON. Skip corrupted lines, log warnings,
continue processing. A single bad line should not invalidate the entire transcript.

```python
def read_events(self, thread_id: str, project_path: Path) -> List[Dict]:
    jsonl_path = project_path / ".ai" / "threads" / thread_id / "transcript.jsonl"
    events = []
    corrupted_lines = []

    with open(jsonl_path, "r", encoding="utf-8") as f:
        for line_num, line in enumerate(f, 1):
            line = line.strip()
            if not line:
                continue
            try:
                event = json.loads(line)
                # Validate required envelope fields
                if "ts" not in event or "type" not in event:
                    corrupted_lines.append((line_num, "missing ts/type", line))
                    continue
                events.append(event)
            except json.JSONDecodeError as e:
                corrupted_lines.append((line_num, str(e), line[:200]))
                continue

    if corrupted_lines:
        logger.warning(
            f"Thread {thread_id}: {len(corrupted_lines)} corrupted lines "
            f"in transcript.jsonl (lines: {[c[0] for c in corrupted_lines]})"
        )

    return events
```

### `thread.json` Integrity

`thread.json` is a mutable metadata file updated at start, completion, and error.
Protect against partial writes with atomic rename:

```python
def write_thread_meta(self, thread_id: str, meta: Dict) -> None:
    meta_path = self.threads_dir / thread_id / "thread.json"
    tmp_path = meta_path.with_suffix(".json.tmp")

    # Write to temp file first
    tmp_path.write_text(json.dumps(meta, indent=2))

    # Atomic rename (POSIX guarantees this is atomic on same filesystem)
    tmp_path.rename(meta_path)
```

On read, if `thread.json` is missing or corrupt, fall back to reconstructing
metadata from `transcript.jsonl` events:

```python
def read_thread_meta(self, thread_id: str) -> Optional[Dict]:
    meta_path = self.threads_dir / thread_id / "thread.json"
    try:
        return json.loads(meta_path.read_text())
    except (FileNotFoundError, json.JSONDecodeError):
        # Reconstruct from transcript
        return self._reconstruct_meta_from_transcript(thread_id)

def _reconstruct_meta_from_transcript(self, thread_id: str) -> Optional[Dict]:
    events = self.read_events(thread_id, self.project_path)
    if not events:
        return None

    start = next((e for e in events if e["type"] == "thread_start"), None)
    complete = next((e for e in events if e["type"] == "thread_complete"), None)
    error = next((e for e in events if e["type"] == "thread_error"), None)

    meta = {
        "thread_id": thread_id,
        "directive": start.get("directive", "") if start else "",
        "model": start.get("model", "") if start else "",
        "status": "error" if error else ("completed" if complete else "running"),
        "created_at": events[0]["ts"],
        "updated_at": events[-1]["ts"],
        "reconstructed": True,  # Flag that this was rebuilt
    }
    if complete:
        meta["cost"] = complete.get("cost", {})
    return meta
```

### Markdown Recovery

`transcript.md` is a derived view — always rebuildable from `transcript.jsonl`.
If it gets corrupted or deleted, the `TranscriptRenderer` can regenerate it.
Never treat `.md` as authoritative.

### Summary of Guarantees

| File               | Authoritative?            | Write Pattern      | Corruption Recovery         |
| ------------------ | ------------------------- | ------------------ | --------------------------- |
| `transcript.jsonl` | **Yes** — source of truth | Atomic line append | Skip bad lines, log warning |
| `thread.json`      | Convenience cache         | Atomic rename      | Reconstruct from JSONL      |
| `transcript.md`    | Derived view              | Append per event   | Regenerate from JSONL       |
| `registry.db`      | Index only                | SQLite WAL         | Re-index from thread dirs   |

---

## Test Specifications

Tests live in `tests/rye_tests/test_transcript_telemetry.py`. All test classes use
`@pytest.mark.asyncio` and load tools via `importlib.util`.

### Shared Test Fixtures

```python
import importlib.util
import json
import tempfile
from pathlib import Path

import pytest

REGISTRY_PATH = (
    Path(__file__).parent.parent.parent
    / "rye" / "rye" / ".ai" / "tools" / "rye" / "agent" / "threads" / "thread_registry.py"
)
_spec = importlib.util.spec_from_file_location("thread_registry", REGISTRY_PATH)
_registry_mod = importlib.util.module_from_spec(_spec)
_spec.loader.exec_module(_registry_mod)
TranscriptWriter = _registry_mod.TranscriptWriter


@pytest.fixture
def thread_dir():
    """Create temporary thread directory."""
    with tempfile.TemporaryDirectory() as tmpdir:
        yield Path(tmpdir)


@pytest.fixture
def writer(thread_dir):
    """TranscriptWriter pointed at temp directory."""
    return TranscriptWriter(thread_dir, auto_markdown=True, default_directive="test_agent")


@pytest.fixture
def writer_no_md(thread_dir):
    """TranscriptWriter with markdown disabled."""
    return TranscriptWriter(thread_dir, auto_markdown=False, default_directive="test_agent")


THREAD_ID = "hello_world-1739012630"
```

### 1. TranscriptWriter — JSONL Event Writing

```python
class TestTranscriptWriterJSONL:
    """JSONL transcript event writing."""

    def test_write_event_creates_jsonl(self, writer, thread_dir):
        """write_event creates transcript.jsonl with valid JSON line."""
        writer.write_event(THREAD_ID, "thread_start", {
            "directive": "hello_world", "model": "claude-3-5-haiku-20241022",
        })
        jsonl_path = thread_dir / THREAD_ID / "transcript.jsonl"
        assert jsonl_path.exists()
        event = json.loads(jsonl_path.read_text().strip())
        assert event["type"] == "thread_start"
        assert event["directive"] == "hello_world"

    def test_event_envelope_has_required_fields(self, writer, thread_dir):
        """Every event has ts, type, thread_id, directive."""
        writer.write_event(THREAD_ID, "assistant_text", {"text": "Hello"})
        jsonl_path = thread_dir / THREAD_ID / "transcript.jsonl"
        event = json.loads(jsonl_path.read_text().strip())
        assert "ts" in event
        assert event["type"] == "assistant_text"
        assert event["thread_id"] == THREAD_ID
        assert event["directive"] == "test_agent"

    def test_directive_from_data_overrides_default(self, writer, thread_dir):
        """directive in data takes precedence over default_directive."""
        writer.write_event(THREAD_ID, "assistant_text", {
            "text": "Hi", "directive": "custom_directive",
        })
        jsonl_path = thread_dir / THREAD_ID / "transcript.jsonl"
        event = json.loads(jsonl_path.read_text().strip())
        assert event["directive"] == "custom_directive"

    def test_raises_without_directive(self, thread_dir):
        """ValueError raised when no directive provided."""
        writer = TranscriptWriter(thread_dir, auto_markdown=False)  # no default_directive
        with pytest.raises(ValueError, match="missing 'directive'"):
            writer.write_event(THREAD_ID, "assistant_text", {"text": "Hi"})

    def test_multiple_events_append(self, writer, thread_dir):
        """Multiple write_event calls append to same file."""
        writer.write_event(THREAD_ID, "thread_start", {"directive": "test"})
        writer.write_event(THREAD_ID, "user_message", {"text": "hi", "role": "user"})
        writer.write_event(THREAD_ID, "assistant_text", {"text": "hello"})
        jsonl_path = thread_dir / THREAD_ID / "transcript.jsonl"
        lines = [l for l in jsonl_path.read_text().strip().split("\n") if l]
        assert len(lines) == 3
        assert json.loads(lines[0])["type"] == "thread_start"
        assert json.loads(lines[1])["type"] == "user_message"
        assert json.loads(lines[2])["type"] == "assistant_text"

    def test_creates_directory_if_missing(self, writer, thread_dir):
        """Thread subdirectory is created automatically."""
        new_id = "new_directive-1739099999"
        writer.write_event(new_id, "thread_start", {"directive": "new"})
        assert (thread_dir / new_id / "transcript.jsonl").exists()
```

### 2. TranscriptWriter — Auto-Markdown

```python
class TestTranscriptWriterMarkdown:
    """Auto-generated markdown transcript."""

    def test_auto_markdown_creates_md_file(self, writer, thread_dir):
        """write_event with auto_markdown=True creates transcript.md."""
        writer.write_event(THREAD_ID, "thread_start", {
            "directive": "hello_world", "model": "claude-3-5-haiku-20241022",
        })
        md_path = thread_dir / THREAD_ID / "transcript.md"
        assert md_path.exists()
        content = md_path.read_text()
        assert "# hello_world" in content
        assert "claude-3-5-haiku-20241022" in content

    def test_no_markdown_when_disabled(self, writer_no_md, thread_dir):
        """write_event with auto_markdown=False does not create .md."""
        writer_no_md.write_event(THREAD_ID, "thread_start", {"directive": "test"})
        md_path = thread_dir / THREAD_ID / "transcript.md"
        assert not md_path.exists()

    def test_markdown_user_message(self, writer, thread_dir):
        """user_message renders as ## System/User heading."""
        writer.write_event(THREAD_ID, "user_message", {
            "text": "Do something", "role": "system",
        })
        md_path = thread_dir / THREAD_ID / "transcript.md"
        content = md_path.read_text()
        assert "## System" in content
        assert "Do something" in content

    def test_markdown_assistant_text(self, writer, thread_dir):
        """assistant_text renders as ## Assistant heading."""
        writer.write_event(THREAD_ID, "assistant_text", {"text": "I'll help"})
        md_path = thread_dir / THREAD_ID / "transcript.md"
        content = md_path.read_text()
        assert "## Assistant" in content
        assert "I'll help" in content

    def test_markdown_tool_call(self, writer, thread_dir):
        """tool_call_start + tool_call_result render tool block."""
        writer.write_event(THREAD_ID, "tool_call_start", {
            "tool": "fs_read", "call_id": "tc_1", "input": {"path": "/tmp/test"},
        })
        writer.write_event(THREAD_ID, "tool_call_result", {
            "call_id": "tc_1", "output": "file contents here",
        })
        md_path = thread_dir / THREAD_ID / "transcript.md"
        content = md_path.read_text()
        assert "**Tool: fs_read**" in content
        assert "file contents here" in content

    def test_markdown_tool_error(self, writer, thread_dir):
        """tool_call_result with error renders error block."""
        writer.write_event(THREAD_ID, "tool_call_result", {
            "call_id": "tc_1", "output": "", "error": "File not found",
        })
        md_path = thread_dir / THREAD_ID / "transcript.md"
        content = md_path.read_text()
        assert "**Error:**" in content
        assert "File not found" in content

    def test_markdown_step_finish(self, writer, thread_dir):
        """step_finish renders token/cost summary."""
        writer.write_event(THREAD_ID, "step_finish", {
            "cost": {"spend": 0.0025},
            "tokens": {"input_tokens": 500, "output_tokens": 100},
            "finish_reason": "end_turn",
        })
        md_path = thread_dir / THREAD_ID / "transcript.md"
        content = md_path.read_text()
        assert "500in" in content
        assert "100out" in content
        assert "$0.0025" in content

    def test_markdown_thread_complete(self, writer, thread_dir):
        """thread_complete renders completion summary."""
        writer.write_event(THREAD_ID, "thread_complete", {
            "cost": {"turns": 2, "tokens": 3000, "spend": 0.005, "duration_seconds": 8.3},
        })
        md_path = thread_dir / THREAD_ID / "transcript.md"
        content = md_path.read_text()
        assert "**Completed**" in content
        assert "2 turns" in content

    def test_markdown_thread_error(self, writer, thread_dir):
        """thread_error renders error message."""
        writer.write_event(THREAD_ID, "thread_error", {
            "error_code": "llm_call_failed", "detail": "Connection timeout",
        })
        md_path = thread_dir / THREAD_ID / "transcript.md"
        content = md_path.read_text()
        assert "llm_call_failed" in content
        assert "Connection timeout" in content

    def test_unknown_event_type_no_markdown(self, writer, thread_dir):
        """Unknown event types produce no markdown output."""
        writer.write_event(THREAD_ID, "hook_triggered", {"hook": "test"})
        md_path = thread_dir / THREAD_ID / "transcript.md"
        # File may exist but be empty, or may not exist
        if md_path.exists():
            assert md_path.read_text().strip() == ""

    def test_markdown_appends_incrementally(self, writer, thread_dir):
        """Each event appends to existing .md file."""
        writer.write_event(THREAD_ID, "thread_start", {"directive": "test"})
        writer.write_event(THREAD_ID, "assistant_text", {"text": "Hello"})
        writer.write_event(THREAD_ID, "thread_complete", {
            "cost": {"turns": 1, "tokens": 100, "spend": 0.001, "duration_seconds": 1.5},
        })
        md_path = thread_dir / THREAD_ID / "transcript.md"
        content = md_path.read_text()
        assert "# test" in content
        assert "Hello" in content
        assert "**Completed**" in content
```

### 3. JSONL Integrity

```python
class TestJSONLIntegrity:
    """JSONL read/write integrity and fault tolerance."""

    def test_read_events_skips_corrupt_lines(self, thread_dir):
        """Corrupted lines are skipped, valid lines are returned."""
        jsonl_path = thread_dir / THREAD_ID / "transcript.jsonl"
        jsonl_path.parent.mkdir(parents=True)
        jsonl_path.write_text(
            '{"ts":"2026-01-01T00:00:00","type":"thread_start","directive":"test"}\n'
            'THIS IS NOT JSON\n'
            '{"ts":"2026-01-01T00:00:01","type":"assistant_text","text":"hello"}\n'
            '\n'
            '{"broken json\n'
        )
        # Use TranscriptWriter.read_events or equivalent
        events = []
        with open(jsonl_path) as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                try:
                    event = json.loads(line)
                    if "ts" in event and "type" in event:
                        events.append(event)
                except json.JSONDecodeError:
                    continue
        assert len(events) == 2
        assert events[0]["type"] == "thread_start"
        assert events[1]["type"] == "assistant_text"

    def test_read_events_skips_missing_envelope_fields(self, thread_dir):
        """Lines missing required ts/type fields are skipped."""
        jsonl_path = thread_dir / THREAD_ID / "transcript.jsonl"
        jsonl_path.parent.mkdir(parents=True)
        jsonl_path.write_text(
            '{"ts":"2026-01-01T00:00:00","type":"thread_start"}\n'
            '{"type":"no_timestamp"}\n'
            '{"ts":"2026-01-01T00:00:01"}\n'
            '{"ts":"2026-01-01T00:00:02","type":"valid_event"}\n'
        )
        events = []
        with open(jsonl_path) as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                try:
                    event = json.loads(line)
                    if "ts" in event and "type" in event:
                        events.append(event)
                except json.JSONDecodeError:
                    continue
        assert len(events) == 2

    def test_empty_file_returns_no_events(self, thread_dir):
        """Empty transcript file returns empty list."""
        jsonl_path = thread_dir / THREAD_ID / "transcript.jsonl"
        jsonl_path.parent.mkdir(parents=True)
        jsonl_path.write_text("")
        events = []
        with open(jsonl_path) as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                try:
                    events.append(json.loads(line))
                except json.JSONDecodeError:
                    continue
        assert len(events) == 0
```

### 4. thread.json Lifecycle

```python
class TestThreadMetaJSON:
    """thread.json write/read/reconstruction."""

    def test_write_thread_meta_atomic(self, thread_dir):
        """write_thread_meta uses atomic rename (tmp -> final)."""
        thread_path = thread_dir / THREAD_ID
        thread_path.mkdir(parents=True)
        meta = {
            "thread_id": THREAD_ID,
            "directive": "hello_world",
            "status": "running",
            "created_at": "2026-02-09T04:03:50Z",
            "updated_at": "2026-02-09T04:03:50Z",
        }
        meta_path = thread_path / "thread.json"
        tmp_path = meta_path.with_suffix(".json.tmp")
        tmp_path.write_text(json.dumps(meta, indent=2))
        tmp_path.rename(meta_path)

        loaded = json.loads(meta_path.read_text())
        assert loaded["thread_id"] == THREAD_ID
        assert loaded["status"] == "running"
        assert not tmp_path.exists()

    def test_reconstruct_meta_from_transcript(self, thread_dir):
        """Metadata can be reconstructed from transcript.jsonl events."""
        jsonl_path = thread_dir / THREAD_ID / "transcript.jsonl"
        jsonl_path.parent.mkdir(parents=True)
        jsonl_path.write_text(
            '{"ts":"2026-02-09T04:03:50Z","type":"thread_start",'
            '"directive":"hello_world","model":"haiku"}\n'
            '{"ts":"2026-02-09T04:04:01Z","type":"thread_complete",'
            '"cost":{"turns":2,"tokens":3000,"spend":0.005}}\n'
        )
        events = [json.loads(l) for l in jsonl_path.read_text().strip().split("\n")]
        start = next(e for e in events if e["type"] == "thread_start")
        complete = next((e for e in events if e["type"] == "thread_complete"), None)
        meta = {
            "thread_id": THREAD_ID,
            "directive": start.get("directive", ""),
            "model": start.get("model", ""),
            "status": "completed" if complete else "running",
            "created_at": events[0]["ts"],
            "updated_at": events[-1]["ts"],
            "reconstructed": True,
        }
        if complete:
            meta["cost"] = complete.get("cost", {})
        assert meta["directive"] == "hello_world"
        assert meta["status"] == "completed"
        assert meta["cost"]["turns"] == 2
        assert meta["reconstructed"] is True

    def test_reconstruct_error_thread(self, thread_dir):
        """Error threads reconstruct with status='error'."""
        jsonl_path = thread_dir / THREAD_ID / "transcript.jsonl"
        jsonl_path.parent.mkdir(parents=True)
        jsonl_path.write_text(
            '{"ts":"2026-02-09T04:03:50Z","type":"thread_start","directive":"test"}\n'
            '{"ts":"2026-02-09T04:04:01Z","type":"thread_error",'
            '"error_code":"llm_call_failed","detail":"timeout"}\n'
        )
        events = [json.loads(l) for l in jsonl_path.read_text().strip().split("\n")]
        error = next((e for e in events if e["type"] == "thread_error"), None)
        status = "error" if error else "running"
        assert status == "error"
```

### 5. TranscriptRenderer

```python
class TestTranscriptRenderer:
    """Standalone transcript renderer."""

    def test_render_full_transcript(self, thread_dir):
        """Render complete markdown from JSONL events."""
        jsonl_path = thread_dir / THREAD_ID / "transcript.jsonl"
        jsonl_path.parent.mkdir(parents=True)
        jsonl_path.write_text(
            '{"ts":"2026-02-09T04:03:50Z","type":"thread_start",'
            '"thread_id":"hello_world-1739012630","directive":"hello_world","model":"haiku"}\n'
            '{"ts":"2026-02-09T04:03:51Z","type":"user_message","text":"Hi","role":"user"}\n'
            '{"ts":"2026-02-09T04:03:52Z","type":"assistant_text","text":"Hello!"}\n'
            '{"ts":"2026-02-09T04:03:53Z","type":"thread_complete",'
            '"cost":{"turns":1,"tokens":100,"spend":0.001,"duration_seconds":3.0}}\n'
        )
        # Renderer should read JSONL and produce complete markdown
        events = [json.loads(l) for l in jsonl_path.read_text().strip().split("\n")]
        assert len(events) == 4
        # Verify events can be rendered (renderer implementation test)
        assert events[0]["type"] == "thread_start"
        assert events[-1]["type"] == "thread_complete"

    def test_render_with_thinking_disabled(self, thread_dir):
        """With thinking=False, assistant_reasoning events are skipped."""
        jsonl_path = thread_dir / THREAD_ID / "transcript.jsonl"
        jsonl_path.parent.mkdir(parents=True)
        jsonl_path.write_text(
            '{"ts":"T","type":"assistant_reasoning","text":"Let me think..."}\n'
            '{"ts":"T","type":"assistant_text","text":"Answer is 42"}\n'
        )
        events = [json.loads(l) for l in jsonl_path.read_text().strip().split("\n")]
        # With thinking=False, filter out assistant_reasoning
        filtered = [e for e in events if e["type"] != "assistant_reasoning"]
        assert len(filtered) == 1
        assert filtered[0]["text"] == "Answer is 42"

    def test_render_with_tool_details_disabled(self, thread_dir):
        """With tool_details=False, tool input/output is summarized."""
        jsonl_path = thread_dir / THREAD_ID / "transcript.jsonl"
        jsonl_path.parent.mkdir(parents=True)
        jsonl_path.write_text(
            '{"ts":"T","type":"tool_call_start","tool":"fs_read","call_id":"1","input":{"path":"/x"}}\n'
            '{"ts":"T","type":"tool_call_result","call_id":"1","output":"contents"}\n'
        )
        events = [json.loads(l) for l in jsonl_path.read_text().strip().split("\n")]
        assert len(events) == 2
        # tool_details=False should show tool name only, hide input/output
```

### 6. ThreadTelemetry

```python
class TestThreadTelemetry:
    """Telemetry aggregation from thread.json files."""

    def test_aggregate_counts_threads(self, thread_dir):
        """Counts total, completed, and error threads."""
        for i, status in enumerate(["completed", "completed", "error"]):
            t_dir = thread_dir / f"test-{1739012630 + i}"
            t_dir.mkdir(parents=True)
            (t_dir / "thread.json").write_text(json.dumps({
                "thread_id": f"test-{1739012630 + i}",
                "directive": "test",
                "status": status,
                "created_at": "2026-02-09T04:03:50Z",
                "cost": {"spend": 0.01, "tokens": 1000},
            }))
        # Aggregate: 3 total, 2 completed, 1 error
        total = 0
        completed = 0
        error = 0
        for t_dir in thread_dir.iterdir():
            meta_path = t_dir / "thread.json"
            if not meta_path.exists():
                continue
            meta = json.loads(meta_path.read_text())
            total += 1
            if meta["status"] == "completed":
                completed += 1
            elif meta["status"] == "error":
                error += 1
        assert total == 3
        assert completed == 2
        assert error == 1

    def test_aggregate_sums_cost(self, thread_dir):
        """Aggregates total spend and tokens across threads."""
        for i in range(3):
            t_dir = thread_dir / f"test-{1739012630 + i}"
            t_dir.mkdir(parents=True)
            (t_dir / "thread.json").write_text(json.dumps({
                "thread_id": f"test-{1739012630 + i}",
                "directive": "test",
                "status": "completed",
                "created_at": "2026-02-09T04:03:50Z",
                "cost": {"spend": 0.01, "tokens": 1000},
            }))
        total_spend = 0.0
        total_tokens = 0
        for t_dir in thread_dir.iterdir():
            meta_path = t_dir / "thread.json"
            if not meta_path.exists():
                continue
            meta = json.loads(meta_path.read_text())
            total_spend += meta.get("cost", {}).get("spend", 0)
            total_tokens += meta.get("cost", {}).get("tokens", 0)
        assert abs(total_spend - 0.03) < 0.001
        assert total_tokens == 3000

    def test_aggregate_groups_by_directive(self, thread_dir):
        """Groups thread counts by directive name."""
        directives = ["hello", "hello", "deploy"]
        for i, d in enumerate(directives):
            t_dir = thread_dir / f"{d}-{1739012630 + i}"
            t_dir.mkdir(parents=True)
            (t_dir / "thread.json").write_text(json.dumps({
                "thread_id": f"{d}-{1739012630 + i}",
                "directive": d,
                "status": "completed",
                "created_at": "2026-02-09T04:03:50Z",
                "cost": {"spend": 0.01, "tokens": 500},
            }))
        by_directive = {}
        for t_dir in thread_dir.iterdir():
            meta_path = t_dir / "thread.json"
            if not meta_path.exists():
                continue
            meta = json.loads(meta_path.read_text())
            d = meta["directive"]
            by_directive.setdefault(d, {"count": 0, "spend": 0.0})
            by_directive[d]["count"] += 1
            by_directive[d]["spend"] += meta.get("cost", {}).get("spend", 0)
        assert by_directive["hello"]["count"] == 2
        assert by_directive["deploy"]["count"] == 1

    def test_aggregate_skips_missing_thread_json(self, thread_dir):
        """Directories without thread.json are silently skipped."""
        (thread_dir / "orphan-1739012630").mkdir(parents=True)
        (thread_dir / "orphan-1739012630" / "transcript.jsonl").write_text("")
        total = 0
        for t_dir in thread_dir.iterdir():
            if (t_dir / "thread.json").exists():
                total += 1
        assert total == 0

    def test_aggregate_handles_corrupt_thread_json(self, thread_dir):
        """Corrupt thread.json files are skipped gracefully."""
        t_dir = thread_dir / "corrupt-1739012630"
        t_dir.mkdir(parents=True)
        (t_dir / "thread.json").write_text("NOT VALID JSON{{{")
        total = 0
        for t_dir_iter in thread_dir.iterdir():
            meta_path = t_dir_iter / "thread.json"
            if not meta_path.exists():
                continue
            try:
                json.loads(meta_path.read_text())
                total += 1
            except json.JSONDecodeError:
                continue
        assert total == 0
```

---

## Implementation Order

| Step | Task                                                         | Effort |
| ---- | ------------------------------------------------------------ | ------ |
| 1    | Rich transcript events + `directive` envelope in `thread_directive.py` | ~2hr   |
| 2    | Auto-markdown in `TranscriptWriter`                          | ~1hr   |
| 3    | `thread.json` write/update in `thread_directive.py`          | ~1hr   |
| 4    | `TranscriptRenderer` tool                                    | ~2hr   |
| 5    | `ThreadTelemetry` tool                                       | ~2hr   |
