<!-- rye:signed:2026-02-18T10:11:13Z:2be19fa436c7e938bb22efe74d1ce024bf3c9bf61c8aefd707bbb4be37022050:ZpMoc2vF2OxGQ-bWIsDBvAs3HAWmjR_270pcZajtL7sHeaER_Qo_r_ZPPElwvlH8jb5oVPvFjPlj7hOiZTXiBQ==:440443d0858f0199 -->
```yaml
id: graphs/graphs/graphs-1771409468
title: "State: graphs (graphs-1771409468)"
entry_type: graph_state
category: graphs/graphs
version: "1.0.0"
graph_id: graphs
graph_run_id: graphs-1771409468
parent_thread_id: 
status: completed
current_node: done
step_count: 5
updated_at: 2026-02-18T10:11:13Z
tags: [graph_state]
```

{
  "inputs": {
    "file_path": "graph-output/full-review/samples/cache.py",
    "output_dir": "graph-output/async-test4",
    "capabilities": [
      "rye.execute.tool.*",
      "rye.execute.directive.*",
      "rye.search.*",
      "rye.load.*",
      "rye.sign.*"
    ],
    "depth": 5
  },
  "source_code": "import time\nfrom collections import OrderedDict\nfrom threading import Lock\n\nclass LRUCache:\n    def __init__(self, capacity: int = 128, ttl: int = 300):\n        self.capacity = capacity\n        self.ttl = ttl\n        self.cache = OrderedDict()\n        self.timestamps = {}\n        self.lock = Lock()\n\n    def get(self, key: str):\n        with self.lock:\n            if key not in self.cache:\n                return None\n            if time.time() - self.timestamps[key] > self.ttl:\n                del self.cache[key]\n                del self.timestamps[key]\n                return None\n            self.cache.move_to_end(key)\n            return self.cache[key]\n\n    def put(self, key: str, value) -> None:\n        with self.lock:\n            if key in self.cache:\n                self.cache.move_to_end(key)\n            self.cache[key] = value\n            self.timestamps[key] = time.time()\n            if len(self.cache) > self.capacity:\n                oldest = next(iter(self.cache))\n                del self.cache[oldest]\n                del self.timestamps[oldest]\n\n    def invalidate(self, key: str) -> bool:\n        with self.lock:\n            if key in self.cache:\n                del self.cache[key]\n                del self.timestamps[key]\n                return True\n            return False\n\n    def clear(self) -> int:\n        with self.lock:\n            count = len(self.cache)\n            self.cache.clear()\n            self.timestamps.clear()\n            return count\n",
  "analysis_result": "I'll analyze the provided code snippet and execute the directive steps.\n\nLet me analyze the code:\n\n1. **Language**: Python\n2. **Function/Method Count**: 5 methods defined in the LRUCache class:\n   - `__init__`\n   - `get`\n   - `put`\n   - `invalidate`\n   - `clear`\n\n3. **Summary**: This code implements an LRU (Least Recently Used) Cache class with TTL (Time To Live) support in Python. The cache stores key-value pairs with a maximum capacity and automatically removes oldest entries when capacity is exceeded, while also expiring entries that exceed their TTL. It uses thread-safe locking to ensure concurrent access safety.\n\nNow I'll execute the directive steps:",
  "thread_id": "test/graphs/analyze_code-1771409468",
  "analysis_json": "{\"language\": \"Python\", \"function_count\": 5, \"summary\": \"This code implements an LRU (Least Recently Used) Cache class with TTL (Time To Live) support. The cache stores key-value pairs with a maximum capacity and automatically removes oldest entries when capacity is exceeded, while also expiring entries that exceed their TTL. It uses thread-safe locking to ensure concurrent access safety.\"}",
  "report_written": true
}